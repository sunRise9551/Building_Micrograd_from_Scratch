# 🔨Building_Micrograd_from_Scratch

- The underlying principles of implementing neural network backpropagation, teachings sourced from [Andrej](https://www.youtube.com/watch?v=VMj-3S1tku0&t=1589s&ab_channel=AndrejKarpathy).
- An “under the hood” knowledge of deep learning: layer details, loss functions, optimization, etc.

# Project Overview
## 🎲Derivatives in Micrograd
- Understand the concept of derivative
- Implement function to calculate derivatives
![image](https://github.com/sunRise9551/Building_Micrograd_from_Scratch/assets/73736246/da8f72bb-5bb2-4638-8654-af06d091bbcd)


## 📦Value Object of Micrograd
- Implement basic operations: sum, substract, multiply, division
- Computre gradients
- Implement of Chain rule in backpropagation

## 🌐Neural Network Architecture
- Build Neurons, Layers, and Multi Layer Perceptron
- Create Activation functions
- Establish forward and backward function
- Construct parameters for gradient update

💡 Using Colab to open can see the directory structure more clearly.
